import os
import torch
import random
import numpy as np
from tqdm import tqdm

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.dataset import get_dataloaders
from src.models.unet import PetSegmentationModel
from src.core.loss import BoundaryTargetedLoss
from src.core.metrics import TrimapIoUMetric
from src.core.scheduler import build_optimizer, build_scheduler
from src.utils.visualizer import ResearchVisualizer


def set_seed(seed=42):
    """[ì™„ë²½í•œ ì¬í˜„ì„± í†µì œ]"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def main():
    # 0. ì „ì—­ í†µì œ ì„¤ì •
    set_seed(42)
    config = {
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "epochs": 500,
        "batch_size": 16,  # 4ê°œ ëª¨ë¸ ë™ì‹œ í•™ìŠµì´ë¯€ë¡œ ì‹¤ì œ VRAMì€ ì•½ 30~40GB ì ìœ  ì˜ˆìƒ
    }

    print(
        f"ğŸš€ Hardware Check: Using {config['device'].upper()} with Concurrent Training"
    )

    # ë°ì´í„°ë¡œë” ìƒì„± (ë‹¨ 1ê°œì˜ ë°°ì¹˜ ìŠ¤íŠ¸ë¦¼)
    train_loader, val_loader = get_dataloaders(batch_size=config["batch_size"])

    # 1. 2x2 ìš”ì¸ ì„¤ê³„ ì‹¤í—˜ ëª©ë¡
    experiments = [
        {"name": "sRGB_ReLU", "use_oklab": False, "use_helu": False},
        {"name": "sRGB_HeLU", "use_oklab": False, "use_helu": True},
        {"name": "OklabP_ReLU", "use_oklab": True, "use_helu": False},
        {"name": "OklabP_HeLU", "use_oklab": True, "use_helu": True},
    ]

    # 2. 4ê°œ ëª¨ë¸ì˜ ë…ë¦½ì ì¸ ê°ì²´ë“¤ì„ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    models = {}
    optimizers = {}
    schedulers = {}
    metrics = {}
    visualizers = {}
    histories = {}
    best_ious = {}

    criterion = BoundaryTargetedLoss(boundary_boost=2.0).to(config["device"])

    print("\nğŸ“¦ Initializing 4 Models into VRAM...")
    for exp in experiments:
        name = exp["name"]
        model = PetSegmentationModel(
            use_oklab=exp["use_oklab"], use_helu=exp["use_helu"]
        ).to(config["device"])

        models[name] = model
        optimizers[name] = build_optimizer(model, base_lr=1e-4)
        schedulers[name] = build_scheduler(optimizers[name], warmup_epochs=5)
        metrics[name] = TrimapIoUMetric(num_classes=3, device=config["device"])
        visualizers[name] = ResearchVisualizer(save_dir=f"outputs/figures/{name}")

        histories[name] = {"train_loss": [], "val_boundary_iou": [], "val_miou": []}
        best_ious[name] = 0.0

    os.makedirs("outputs/weights", exist_ok=True)

    # 3. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ë™ì‹œ í•™ìŠµ ë£¨í”„)
    for epoch in range(1, config["epochs"] + 1):
        print(f"\n{'='*60}\nğŸ Epoch[{epoch}/{config['epochs']}]\n{'='*60}")

        # -------------------[TRAIN PHASE] -------------------
        for name in models:
            models[name].train()

        train_losses = {name: 0.0 for name in models}

        pbar = tqdm(train_loader, desc="[Train]", leave=False)
        for imgs, masks in pbar:
            imgs, masks = imgs.to(config["device"]), masks.to(config["device"])

            # ë‹¨ì¼ ë°°ì¹˜ë¥¼ 4ê°œ ëª¨ë¸ì´ ë™ì‹œì— ë¨¹ê³  ê°ê° ì—­ì „íŒŒ ìˆ˜í–‰
            for name, model in models.items():
                optimizers[name].zero_grad()
                outputs = model(imgs)
                loss = criterion(outputs, masks)
                loss.backward()
                optimizers[name].step()

                train_losses[name] += loss.item()

        # Train ì—í­ ì¢…ë£Œ ì²˜ë¦¬
        for name in models:
            avg_train_loss = train_losses[name] / len(train_loader)
            histories[name]["train_loss"].append(avg_train_loss)
            schedulers[name].step()

        # -------------------- [VAL PHASE] --------------------
        for name in models:
            models[name].eval()
            metrics[name].reset()

        with torch.no_grad():
            for i, (imgs, masks) in enumerate(
                tqdm(val_loader, desc="[Valid]", leave=False)
            ):
                imgs, masks = imgs.to(config["device"]), masks.to(config["device"])

                for name, model in models.items():
                    outputs = model(imgs)
                    metrics[name].update(outputs, masks)

                    # ì—í­ë³„ ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ 4ê°œ ëª¨ë¸ ëª¨ë‘ ì‹œê°í™”ìš© ì´ë¯¸ì§€ ì¶”ì¶œ
                    if i == 0:
                        preds = torch.argmax(outputs, dim=1)
                        visualizers[name].save_prediction_grid(
                            epoch,
                            imgs.cpu(),
                            masks.cpu(),
                            preds.cpu(),
                            filename=f"epoch_{epoch:03d}.png",
                        )

        # -----------------[LOGGING & SAVE] -----------------
        print(f"\nğŸ“Š Epoch [{epoch}] Summary:")
        for name in models:
            res = metrics[name].compute()
            b_iou = res["iou_boundary"]
            m_iou = res["miou"]
            current_lr = schedulers[name].get_last_lr()[0]

            histories[name]["val_boundary_iou"].append(b_iou)
            histories[name]["val_miou"].append(m_iou)

            # ê²°ê³¼ ì¶œë ¥ (í„°ë¯¸ë„ì—ì„œ 4ê°œ ëª¨ë¸ì„ í•œëˆˆì— ë¹„êµ)
            print(
                f"  [{name:<12}] Loss: {histories[name]['train_loss'][-1]:.4f} | "
                f"LR: {current_lr:.2e} | mIoU: {m_iou:.4f} | Boundary IoU: {b_iou:.4f}"
            )

            # ìµœê³  ì„±ëŠ¥ ê°±ì‹  ì‹œ ê°€ì¤‘ì¹˜ ì €ì¥ (ì˜¤ì§ ê²½ê³„ì„  IoU ê¸°ì¤€)
            if b_iou > best_ious[name]:
                best_ious[name] = b_iou
                save_path = f"outputs/weights/{name}_best.pth"
                torch.save(models[name].state_dict(), save_path)
                print(f"      â­ {name} updated best weights! (B-IoU: {b_iou:.4f})")

    # 4. ìµœì¢… ë…¼ë¬¸ìš© 4ìƒ‰ ê·¸ë˜í”„ ë Œë”ë§
    print("\nğŸ¨ Rendering Final Convergence Graph for Paper...")
    final_visualizer = ResearchVisualizer(save_dir="outputs/figures")

    # ì‹œê°í™” í•¨ìˆ˜ ìš”êµ¬ í¬ë§·ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ ë³€í™˜
    plot_data = {
        name: {"boundary_iou": hist["val_boundary_iou"]}
        for name, hist in histories.items()
    }

    final_visualizer.plot_4model_iou_curves(
        plot_data, warmup_epochs=5, filename="Final_Boundary_IoU_Convergence.pdf"
    )
    print("âœ… All 4 Experiments Completed Concurrently!")


if __name__ == "__main__":
    main()
