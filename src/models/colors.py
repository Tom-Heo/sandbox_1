import os
import torch
import random
import numpy as np
from tqdm import tqdm

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.dataset import get_dataloaders
from src.models.unet import PetSegmentationModel
from src.core.loss import BoundaryTargetedLoss
from src.core.metrics import TrimapIoUMetric
from src.core.scheduler import build_optimizer, build_scheduler
from src.utils.visualizer import ResearchVisualizer


def set_seed(seed=42):
    """[ì™„ë²½í•œ ì¬í˜„ì„± í†µì œ]
    ìš´(Luck)ì´ ê°œì…í•  ì—¬ì§€ë¥¼ ì›ì²œ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def train_single_model(exp_name, use_oklab, use_helu, dataloaders, config):
    """ë‹¨ì¼ ëª¨ë¸ì˜ í•™ìŠµë¶€í„° í‰ê°€, ì‹œê°í™”, ê°€ì¤‘ì¹˜ ì €ì¥ê¹Œì§€ ì±…ì„ì§€ëŠ” íŒŒì´í”„ë¼ì¸"""
    print(f"\n{'='*50}\nğŸš€ Starting Experiment: {exp_name}\n{'='*50}")

    device = config["device"]
    epochs = config["epochs"]
    train_loader, val_loader = dataloaders

    # 1. ì•„í‚¤í…ì²˜, ì†ì‹¤í•¨ìˆ˜, í‰ê°€ë§, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì„¸íŒ…
    model = PetSegmentationModel(use_oklab=use_oklab, use_helu=use_helu).to(device)
    criterion = BoundaryTargetedLoss(boundary_boost=2.0).to(device)
    metric = TrimapIoUMetric(num_classes=3, device=device)
    visualizer = ResearchVisualizer(save_dir=f"outputs/figures/{exp_name}")

    optimizer = build_optimizer(model, base_lr=1e-4)
    scheduler = build_scheduler(optimizer, warmup_epochs=5)

    best_boundary_iou = 0.0
    history = {"train_loss": [], "val_boundary_iou": [], "val_miou": []}

    for epoch in range(1, epochs + 1):
        # ------------------- [TRAIN PHASE] -------------------
        model.train()
        train_loss = 0.0

        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{epochs} [Train]", leave=False)
        for imgs, masks in pbar:
            imgs, masks = imgs.to(device), masks.to(device)

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, masks)

            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            pbar.set_postfix({"loss": f"{loss.item():.4f}"})

        avg_train_loss = train_loss / len(train_loader)
        scheduler.step()  # ì—í­ ì¢…ë£Œ í›„ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸

        # -------------------- [VAL PHASE] --------------------
        model.eval()
        metric.reset()

        with torch.no_grad():
            for i, (imgs, masks) in enumerate(val_loader):
                imgs, masks = imgs.to(device), masks.to(device)
                outputs = model(imgs)
                metric.update(outputs, masks)

                # ì—í­ë³„ ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì‹œê°í™”ìš© ì´ë¯¸ì§€ ì¶”ì¶œ (ì¶”ì´ ê´€ì°°ìš©)
                if i == 0:
                    preds = torch.argmax(outputs, dim=1)
                    visualizer.save_prediction_grid(
                        epoch,
                        imgs.cpu(),
                        masks.cpu(),
                        preds.cpu(),
                        filename=f"epoch_{epoch:03d}.png",
                    )

        metrics = metric.compute()
        b_iou = metrics["iou_boundary"]

        history["train_loss"].append(avg_train_loss)
        history["val_boundary_iou"].append(b_iou)
        history["val_miou"].append(metrics["miou"])

        print(
            f"Epoch[{epoch}/{epochs}] "
            f"Loss: {avg_train_loss:.4f} | "
            f"LR: {scheduler.get_last_lr()[0]:.2e} | "
            f"mIoU: {metrics['miou']:.4f} | "
            f"Boundary IoU: {b_iou:.4f}"
        )

        # ----------------- [EARLY STOPPING & SAVE] -----------------
        # ì¡°ê¸° ì¢…ë£Œ ë° ê°€ì¤‘ì¹˜ ì €ì¥ì˜ ê¸°ì¤€ì€ ì˜¤ì§ 'ê²½ê³„ì„ (Boundary) IoU'ì…ë‹ˆë‹¤.
        if b_iou > best_boundary_iou:
            best_boundary_iou = b_iou
            os.makedirs("outputs/weights", exist_ok=True)
            save_path = f"outputs/weights/{exp_name}_best.pth"
            torch.save(model.state_dict(), save_path)
            print(f"ğŸŒŸ Best Model Saved! (Boundary IoU: {best_boundary_iou:.4f})")

    return history


def main():
    # 0. ì „ì—­ í†µì œ ì„¤ì •
    set_seed(42)
    config = {
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "epochs": 50,  # ì—°êµ¬ ëª©ì ì´ë¯€ë¡œ ì¶©ë¶„íˆ ê¸¸ê²Œ ëŒë¦½ë‹ˆë‹¤.
        "batch_size": 16,  # ê¸°ìš¸ê¸° ë…¸ì´ì¦ˆ ë³´ì¡´ì„ ìœ„í•´ 16ìœ¼ë¡œ í†µì œ
    }

    print(f"Hardware Check: Using {config['device'].upper()}")

    # ë°ì´í„°ë¡œë”ëŠ” ë‹¨ í•œ ë²ˆë§Œ ìƒì„±í•˜ì—¬ 4ê°œ ëª¨ë¸ì´ ì™„ì „íˆ ë™ì¼í•œ ë‚œìˆ˜ ë°°ì¹˜ë¥¼ ë¨¹ê²Œ í•©ë‹ˆë‹¤.
    dataloaders = get_dataloaders(batch_size=config["batch_size"])

    # 1. 2x2 ìš”ì¸ ì„¤ê³„ (Factorial Design) ì‹¤í—˜ ëª©ë¡
    experiments = [
        {"name": "sRGB_ReLU", "use_oklab": False, "use_helu": False},
        {"name": "sRGB_HeLU", "use_oklab": False, "use_helu": True},
        {"name": "OklabP_ReLU", "use_oklab": True, "use_helu": False},
        {"name": "OklabP_HeLU", "use_oklab": True, "use_helu": True},
    ]

    all_histories = {}

    # 2. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ìˆœì°¨ í•™ìŠµ)
    for exp in experiments:
        history = train_single_model(
            exp_name=exp["name"],
            use_oklab=exp["use_oklab"],
            use_helu=exp["use_helu"],
            dataloaders=dataloaders,
            config=config,
        )
        # ì‹œê°í™” íˆ´ í¬ë§·ì— ë§ê²Œ ë³€í™˜
        all_histories[exp["name"]] = {
            "boundary_loss": history[
                "train_loss"
            ]  # ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ train_lossë¥¼ ëŒ€í‘œë¡œ ì‚¬ìš©
        }

    # 3. ìµœì¢… ë…¼ë¬¸ìš© 4ìƒ‰ ê·¸ë˜í”„ ë Œë”ë§
    print("\nğŸ¨ Rendering Final Convergence Graph for Paper...")
    final_visualizer = ResearchVisualizer(save_dir="outputs/figures")
    final_visualizer.plot_4model_loss_curves(
        all_histories, warmup_epochs=5, filename="Final_Loss_Convergence.pdf"
    )
    print("âœ… All Experiments Completed Successfully!")


if __name__ == "__main__":
    main()
